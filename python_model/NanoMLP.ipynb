{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52606c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3871adfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在准备 MNIST 数据集...\n",
      "开始训练 (演示目的只跑 1 个 Epoch)...\n",
      "Train Step: 0/938 Loss: 2.3047\n",
      "Train Step: 100/938 Loss: 0.5351\n",
      "Train Step: 200/938 Loss: 0.3355\n",
      "Train Step: 300/938 Loss: 0.2733\n",
      "Train Step: 400/938 Loss: 0.1668\n",
      "Train Step: 500/938 Loss: 0.2172\n",
      "Train Step: 600/938 Loss: 0.5041\n",
      "Train Step: 700/938 Loss: 0.3997\n",
      "Train Step: 800/938 Loss: 0.2389\n",
      "Train Step: 900/938 Loss: 0.1404\n",
      "\n",
      "正在导出 ONNX 模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\XieYongyu\\AppData\\Local\\Temp\\ipykernel_36532\\979594530.py:84: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W0103 20:59:15.564000 36532 site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n",
      "Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\FILE\\course\\javaFX\\code\\.conda\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\FILE\\course\\javaFX\\code\\.conda\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"d:\\FILE\\course\\javaFX\\code\\.conda\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\FILE\\course\\javaFX\\code\\.conda\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $14 for Reshape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行兼容性降级处理 (IR Version 10 -> 9)...\n",
      "处理完成！兼容型模型已保存为: d:\\FILE\\course\\javaFX\\code\\nano_mlp.onnx\n",
      "请将此新文件覆盖到 Java 项目的 src/main/resources/models/ 中\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. 定义 NanoMLP 模型 (核心修改点)\n",
    "# ==========================================\n",
    "class NanoMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NanoMLP, self).__init__()\n",
    "        # 输入层 784 (28x28) -> 隐藏层 32 [cite: 4, 11, 12]\n",
    "        self.fc1 = nn.Linear(784, 32)\n",
    "        # 隐藏层 32 -> 输出层 10 [cite: 13]\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 展平输入 (Batch_Size, 1, 28, 28) -> (Batch_Size, 784)\n",
    "        x = x.view(-1, 784)\n",
    "        \n",
    "        # 计算隐藏层 (这是我们要可视化的\"特征频谱\")\n",
    "        # 使用 ReLU 激活函数 [cite: 12]\n",
    "        hidden = torch.relu(self.fc1(x))\n",
    "        \n",
    "        # 计算输出层\n",
    "        output = self.fc2(hidden)\n",
    "        \n",
    "        # 使用 Softmax 获取概率分布 [cite: 13]\n",
    "        prob = torch.softmax(output, dim=1)\n",
    "        \n",
    "        # 关键点：必须同时返回 prob 和 hidden \n",
    "        # 这样 Java 端才能拿到中间层的 32 个数值画出条形码\n",
    "        return prob, hidden\n",
    "# ==========================================\n",
    "# 2. 准备数据与训练\n",
    "# ==========================================\n",
    "def train():\n",
    "    print(\"正在准备 MNIST 数据集...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)) # 标准化\n",
    "    ])\n",
    "    \n",
    "    # 下载训练数据\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    model = NanoMLP()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"开始训练 (演示目的只跑 1 个 Epoch)...\")\n",
    "    model.train()\n",
    "    \n",
    "    # 简单的训练循环\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # 注意：因为 forward 返回两个值，我们这里只需要第一个值(prob)来计算 Loss\n",
    "        # 但 CrossEntropyLoss 通常接收 raw logits，为了简化，这里我们做个适配\n",
    "        # 或者为了更标准的训练，我们可以暂时用 output 而不是 prob 训练\n",
    "        # 但为了保证导出逻辑一致，我们直接计算 loss\n",
    "        \n",
    "        prob, _ = model(data) \n",
    "        # CrossEntropyLoss 期望 logits，但如果用 NLLLoss 则配合 log_softmax\n",
    "        # 这里为了演示简单，我们手动计算 NLL \n",
    "        loss = -torch.log(prob[range(target.shape[0]), target]).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Step: {batch_idx}/{len(train_loader)} Loss: {loss.item():.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 3. 导出 ONNX (技术闭环关键)\n",
    "# ==========================================\n",
    "def export_onnx(model):\n",
    "    print(\"\\n正在导出 ONNX 模型...\")\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. 准备输入\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    output_path = \"nano_mlp.onnx\"\n",
    "    \n",
    "    # 2. 导出模型 (先使用 Opset 11，这是一个非常稳定且兼容性极好的版本)\n",
    "    # 这一步通常不会报错，因为它不需要复杂的 14->12 转换\n",
    "    torch.onnx.export(\n",
    "        model, \n",
    "        (dummy_input,),\n",
    "        output_path,\n",
    "        verbose=False,\n",
    "        input_names=['input'], \n",
    "        output_names=['prob', 'hidden'],\n",
    "        opset_version=11,  # <--- 改用 11，避开 14->12 的转换 bug\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, \n",
    "                      'prob': {0: 'batch_size'}, \n",
    "                      'hidden': {0: 'batch_size'}}\n",
    "    )\n",
    "    \n",
    "    # 3. 【关键修复】手动修改 IR Version\n",
    "    # 之前的报错是因为你的 Python 生成了 IR v10，但 Java 只支持 IR v9\n",
    "    # 我们加载模型，强制把“版本号”改写为 9，然后重新保存。\n",
    "    print(\"正在进行兼容性降级处理 (IR Version 10 -> 9)...\")\n",
    "    \n",
    "    onnx_model = onnx.load(output_path)\n",
    "    onnx_model.ir_version = 9  # <--- 强制设置为 Java 能识别的版本\n",
    "    onnx.save(onnx_model, output_path)\n",
    "    \n",
    "    print(f\"处理完成！兼容型模型已保存为: {os.path.abspath(output_path)}\")\n",
    "    print(\"请将此新文件覆盖到 Java 项目的 src/main/resources/models/ 中\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trained_model = train()\n",
    "    export_onnx(trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "785a3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 Notebook 单元格里运行\n",
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
